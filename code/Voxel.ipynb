{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "import math\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import namedtuple\n",
    "from ase.io import read\n",
    "from ase.build import molecule\n",
    "from ase import Atoms, Atom\n",
    "from ase.visualize import view\n",
    "from ase.geometry.analysis import Analysis\n",
    "import plotly.graph_objects as go\n",
    "from ase.data import vdw_radii\n",
    "from ase.data.colors import cpk_colors, jmol_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from soap_generation.alignment import align_elements\n",
    "from soap_generation.augment import augment_elements\n",
    "\n",
    "from voxel.generator import VoxelGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "barriers = dict()\n",
    "\n",
    "with open('../data/vaskas_features_properties_smiles_filenames.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        #images.append(row[0])\n",
    "        #elos.append(row[1])\n",
    "        barriers[row[93]] = float(row[91])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "elems = []\n",
    "for f in tqdm(os.listdir(\"../data/coordinates_molSimplify/\")):\n",
    "    if f.endswith(\".xyz\"):\n",
    "        if (f == \"ir_tbp_1_dft-pet3_1_dft-py_1_dft-hicn_1_fluoride_1_smi1_1_s_1.xyz\"):\n",
    "            print(\"1:\" + str(len(labels)))\n",
    "\n",
    "        if (f == \"ir_tbp_1_dft-pet3_1_dft-py_1_dft-hicn_1_dft-cn_1_smi1_1_s_1.xyz\"):\n",
    "            print(\"2:\" + str(len(labels)))\n",
    "        elems.append(read(\"../data/coordinates_molSimplify/\" + f))\n",
    "        labels.append(barriers[f[:-4]])\n",
    "\n",
    "labels = np.array(labels)\n",
    "number_samples = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = align_elements(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = [\"H\",\"C\",\"N\",\"O\",\"F\",\"P\",\"S\",\"Cl\",\"As\",\"Br\",\"I\",\"Ir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_gen = VoxelGenerator(species, scale=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "elems_voxel = voxel_gen.generate_voxel(elems[:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-sculpture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "X, Y, Z = np.mgrid[0:100:100j, 0:100:100j, 0:100:100j]\n",
    "values = voxel_rep[0]\n",
    "\n",
    "fig = go.Figure(data=go.Volume(\n",
    "    x=X.flatten(),\n",
    "    y=Y.flatten(),\n",
    "    z=Z.flatten(),\n",
    "    value=values.flatten(),\n",
    "    isomin=0.1,\n",
    "    isomax=0.8,\n",
    "    opacity=0.1, # needs to be small to see through all surfaces\n",
    "    surface_count=17, # needs to be a large number for good volume rendering\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-concentrate",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels).reshape(-1,1)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(\n",
    "        elems_voxel, labels[:60], test_size=0.2, random_state=32)\n",
    "\n",
    "(testX, valX, testY, valY) = train_test_split(\n",
    "        testX, testY, test_size=0.5, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(hp):\n",
    "    input_shape = trainX[0].shape\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    print(inputs)\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    for i in range(hp.Int('conv_layer', 1, 6, default=3)):\n",
    "        kernel = hp.Int('kernel_size_' + str(i), 3, 50)\n",
    "        filters = hp.Int('num_filter_' + str(i), 1, 32)\n",
    "        \n",
    "        x = tf.keras.layers.Conv3D(filters, kernel, activation='relu', kernel_initializer='he_uniform')(x)\n",
    "    \n",
    "        pooling = hp.Choice('pooling_' + str(i), values=[True, False])\n",
    "        \n",
    "        if pooling:\n",
    "            pool = hp.Int('pooling_size_' + str(i), 2, 10)\n",
    "            x = tf.keras.layers.MaxPooling3D(pool_size=(pool, pool, pool))(x)\n",
    "    \n",
    "    \n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "\n",
    "    for i in range(hp.Int('hidden_layers', 1, 6, default=3)):\n",
    "        size = hp.Int('hidden_size_' + str(i), 10, 700, step=40)\n",
    "        reg = hp.Float('hidden_reg_' + str(i), 0,\n",
    "                       0.06, step=0.01, default=0.02)\n",
    "        dropout = hp.Float('hidden_dropout_' + str(i),\n",
    "                           0, 0.5, step=0.1, default=0.2)\n",
    "\n",
    "        x = tf.keras.layers.Dense(size, activation=\"relu\",\n",
    "                                  kernel_regularizer=regularizers.l2(reg))(x)\n",
    "        x = tf.keras.layers.Dropout(dropout)(x)\n",
    "\n",
    "        norm = hp.Choice('hidden_batch_norm_' + str(i), values=[True, False])\n",
    "\n",
    "        if norm:\n",
    "            x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(1, kernel_regularizer='l2')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Float('learning_rate', 1e-6, 1e-4, sampling='log')),\n",
    "        loss='mean_squared_error',\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kerastuner.tuners import Hyperband\n",
    "import kerastuner as kt\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    get_model,\n",
    "    objective='val_mean_squared_error',\n",
    "    max_epochs=1200,\n",
    "    project_name=\"Hyperband_VOXEL_100\",\n",
    "    directory=\"/pfs/work7/workspace/scratch/utpqw-data-0/hyperband_voxel/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.array(trainX)\n",
    "trainY = np.array(trainY)\n",
    "valX = np.array(valX)\n",
    "valY = np.array(valY)\n",
    "testX = np.array(testX)\n",
    "testY = np.array(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(trainX, trainY,\n",
    "             validation_data=(valX, valY),\n",
    "             epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confidential-glasgow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
