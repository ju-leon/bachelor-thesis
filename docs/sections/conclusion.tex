%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.5, 2020-06-26

\chapter{Conclusion}
\label{ch:Conclusion}
In chapter \ref{ch:features}, two different approaches at encoding a molecule into machine learning compatible features are introduced.
On the features produced by the descriptors, regression using neural networks is performed.

While both methods allow for predictions with high accuracy, the results on SNAP features are more promising.
Despite the output not being fully rotational invariant, the network seems to be able to abstract the rotation away with high accuracy.

One of the key differences between the features generated by the descriptors is their information about 
different species.
While the LEFD descriptor only describes the overall shape of the element, it does not encode any information about the 
type of atom in each layer.
The species included in a layer are only implicitly encoded by their unique Van-der-Waals radius, but no explicit information about the 
atom itself is encoded.
While SNAP also encodes the general shape of the element, it does so for every species separately.

Just from features generated from the shape alone the prediction accuracy is already on a par with other machine learning methods performed on autocorrelation features.
This leads to the conclusion that the shape of a catalyst is significant to its activation barrier.
Even without any direct information about the chemical properties, the regression on LEFD features achieved similar accuracies to
the best neural networks on autocorrelation features that encode chemical properties \cite{friederich_dos}.
SNAP neural networks achieve the highest accuracies to date on this dataset, with 
$MAE = 0.52980 kcal/mol$ and $r^2=0.96231$ when trained on 80\% of the training data.

One major concern about this interpretation is the relatively small size of the dataset in combination 
with its combinatorial generation.
The high accuracy of the network raises concerns about the diversity of the dataset.
The possibility of the network learning structure in the dataset, e.g. different ligand combinations,
rather than the structure of the chemical space cannot be ruled out.
While booth, a validation set during training and a test set after training were used to counter these issues,
the dataset needs to be extended with further ligands in the future to draw a more definite conclusion.

In the future the feature generators might be used to encode additional information about the elements.
Possible features that might be encoded by SNAP in addition to the density could include information about 
electro negativity or even more advanced information like the interaction of different atoms.
This additional information might help to further increase the accuracy of the prediction.

While this work was focused on the activation barrier of an element only,
in theory this approach could be used for many other hard to compute properties of molecules.
With similar feature generation and regression methods, it might be possible 
to predict other features from the molecule with relatively low effort.
\\

In a last step, the feature space was discovered to make sense of a models prediction.
Analyzing the origin of the networks prediction gave mixed results.
While it is possible to get an intuition about the global influence of different elements on
the prediction, the local interpretability suffered from the low resolution of the encoding.
Getting an intuition about the influence of different species to the activation barrier is possible.
If these intuitions hold true in the real world will have to be confirmed by further experiments.

\section{Outlook}

Since the size of the dataset is relatively small, possible solutions to increase the accuracy of the predcition might be to 
increase the size of the dataset.
The computation of the activation barrier for these elements might be too costly, instead the structure with some easy to compute 
properties of the elements could be generated for each element.
This would enable the generation of large numbers of catalysts with different shapes.
In a first step, a network could then be trained to predict some of the easy to compute properties of the catalysts from their shape.
The hypothesis is that this will allows the network to learn about the chemical structure of a catalyst.
In a second step, the network architecture would then be slightly adapted to now predict the activation barrier.
However the weights and biases for layers that are kept should not be changed.
The network is then trained on the small dataset where the activation barrier for each element is known.
In the hope that the first training iteration helped the network to better understand the chemical structure of the element,
this might help finding a better local minima for the network predicting the activation barrier, and therefore increase the prediction accuracy.
\\

If a local interpretation of the molecule is required, SNAP might have to be exchanged in favour of a higher resolution 
feature generator.
Other methods of encoding 3D spaces could include voxel representations.
Using spherical gaussians similar to SNAP to encode density of atoms and other information about the molecule are thinkable.
This 3D space could then be rasterized on a voxel grid.
A possible problem with voxel representations would again be creating a model invariant to rotation.
While this sounded counter intuitive at first, SNAP has shown that rotational invariance can be achieved using data augmentations.
Data augmentation on 3D voxel representations in convolutional neural networks seems to achieve high accuracies in 
other fields \cite{7353481}.
Voxel representations could therefore be a possible solution to further increasing interpretability of the model.

The possibility of mapping both ways between the real world and features opens up new possibilities 
used in other areas of machine learning.
It allows for many different approaches to better understand properties of chemical elements, 
and might help with computational element discovery.
\\
When the features produced from the chemical space can be interpreted,
using neural network based techniques such as auto encoders or generative adversarial neural networks (GANs) are thinkable.
Both autoencoders and GANs are machine learning methods that can be used to produce never seen before data with similar properties
to the training data.
For image generation, GANs and autoencoders have proven to generate output that is virtually indistinguishable from real data \cite{karras2019stylebased} .
Using these techniques, but applying them to features of catalysts, rather than to images, computational generation of catalyst molecules is thinkable.
The approach is again limited by the accuracy of mapping between chemical space and feature space.

The accuracies achieved by the models trained on SNAP features indicate that 
the majority of information needed to predict the activation barrier is encoded into the SNAP features.
This does not imply it holds true for other properties of the molecule.
In the future, the SNAP features might be aggregated with other properties of the molecule.
Possible ways to add more information to the SNAP features is to encode the space surrounding the 
central atom in the same way as it is encoded now, but instead of encoding density information encoding 
other molecular properties, such as electro negativity.
The low resolution of the SNAP descriptor will remain a challenge.

In conclusion the SNAP feature extractor shows that data augmentation is possible in chemical spaces.
Feature generators that allow for a bi-directional mapping between features and chemical space can achieve similar or higher
accuracies to state-of-the-art one-directional feature extractors.
This allows for the use of network explainers that can give insight into the origin of chemical properties.
Currently the resolution of feature extractors is the limiting factor to interpretability.