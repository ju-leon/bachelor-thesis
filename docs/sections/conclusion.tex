%% LaTeX2e class for student theses
%% sections/conclusion.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.5, 2020-06-26

\chapter{Conclusion}
\label{ch:Conclusion}
In chapter \ref{ch:features} 2 different approaches at encoding a molecule into computer readable features are introduced.
On the features produced by the descriptors, regression using neural networks is performed.

While both methods allow for predictions with high accuracy, the results on SNAP features are more promising.
Despite the output not being fully rotational invariant, the network seems to be able to abstract the rotation away with high accuracy.

One of the key differences between the features generated by the descriptors is their information about 
different species.
While the LEFD descriptor only describes the overall shape of the element, it does not encode any information about the 
type of atom in each layer.
The species included in a layer are only implicitly encoded by their unique Van-der-Waals radius, but no explicit information about the 
atom itself is encoded.
While SNAP also encodes the general shape of the element, it so for every species separately.

However just from the shape alone the prediction accuracy is already on par with other machine learning methods performed on autocorrelation features.
This leads to the conclusion that the shape of a catalyst plays a significant role in it's activation barrier.
Even without any direct information about the chemical properties, the regression on LEFD features achieved higher accuracies than
the best neural networks on autocorrelation features that encode chemical properties \cite{friederich_dos},
and SNAP neural networks achieve the highest accuracies to date on this dataset.
This shows that machine learning is viable alternative to calculation of the activation barrier.

One mayor concern about this interpretation is the relatively small size of the dataset in combination 
with its combinatorial generation.
The high accuracy of the network raises concerns about the diversity of the dataset.
The possibility of the network learning structure in the dataset, e.g. different ligand combinations,
rather than the structure of the chemical space cannot be ruled out.
While booth, a validation set during training and a test set after training were used to counter these issues,
the dataset needs to be extended with further ligands in the future to draw a more definite conclusion.

In the future the feature generators might be used to encode additional information about the elements.
Possible features that might be encoded by SNAP in addition to the density could include information about 
electro negativity or even more advanced information like the interaction of different atoms.
This additional information might help to further increase the accuracy of the prediction.

While this work was focused on the activation barrier of an element only,
in theory this approach could be used for many other hard to compute properties of molecules.
With similar feature generation and regression methods, it might be possible 
predict other features from the molecule with relatively low effort.
\\

In a last step, we tried to discover the feature space to make sense of the model prediction.
Analyzing the origin of the networks prediction gave mixed results.
While it is possible to get an intuition about the global influence of different elements on
the prediction, the local interpretability suffered from the low resolution of the encoding.
Getting an intuition about the influence of different species to the activation barrier is possible.
If these intuitions hold true in the real world will have to be confirmed by further experiments.

If a local interpretation of the molecule is required, SNAP might have to exchanged in favour of a higher resolution 
feature generator.
Other methods of encoding 3D spaces could include voxel representations.
Using spherical gaussians similar to SNAP to encode density of atoms and other information about the molecule are thinkable.
This 3d space could then be rasterized on a voxel grid.
A possible problem with voxel representations would again be creating a model invariant to rotation.
While this sounded counter intuitive at first, SNAP has shown that rotational invariance can be achieved using data augmentations.
Data augmentation on 3D voxel representations in convolutional neural networks seems to achieve high accuracies in 
other fields \cite{7353481}.
Voxel representations could therefore be a possible solution to further increasing interpretability of the model.

\section{Outlook}

The possibility of mapping both ways between the real world and SNAP features is what set the SNAP feature generator apart 
from many other chemical feature generators.
It allows for many different approaches to computational element discovery.
\\
Another area where SNAP features could be used is auto encoders or generative adversarial neural networks (GANs).
Both autoencoders and GANs are machine learning methods that can be used to produce never seen before data with similar properties
to the training data.
GANs and autoencoders have recently become very popular in image synthesis for their ability to generate synthetic images 
virtually indistinguishable from real pictures \cite{karras2019stylebased} .
Using these techniques, but applying them to SNAP features of catalysts, rather than to images, synthesis 
of catalyst molecules is thinkable.
The approach is again limited by the accuracy of mapping between chemical space and feature space.
Another factor to be considered is if SNAP features actually encode all relevant information needed.

While the accuracies achieved by the models trained on SNAP features indicate that 
the majority of information needed to predict the activation barrier is encoded into the SNAP features, this does
not imply it holds true for other properties of the molecule.
In the future, the SNAP features might be aggregated with other properties of the molecule.
Possible ways to add more information to the SNAP features is to encode the space surrounding the 
central atom in the same way it is encoded now, but instead of encoding density information encoding 
other molecular properties, such as electro negativity.

While convolution layers did not prove effective in for the current SNAP features,
when changing the feature space encoded by snap, and therefor the dimensionality of the input vector,
convolutions might become relevant again.

In conclusion the SNAP feature extractor shows that data augmentation is possible in chemical spaces, and therefore 
feature generators that allow for a bi-directional mapping between features and chemical space can achieve similar or higher
accuracies to state-of-the-art one-directional feature extractors.
This allows for the use of bi-directional feature encoders in computational exploration and generation of chemical structures.
%TODO: Transfer LEarn